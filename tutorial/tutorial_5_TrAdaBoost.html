<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>tutorial_5_TrAdaBoost</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzkiIGhlaWdodD0iNTEiIHZpZXdCb3g9IjAgMCAzOSA1MSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgtMTYzOCAtMjI4MSkiPgogICAgIDxnIGNsYXNzPSJqcC1qdXB5dGVyLWljb24tY29sb3IiIGZpbGw9IiNGMzc3MjYiPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjM5Ljc0IDIzMTEuOTgpIiBkPSJNIDE4LjI2NDYgNy4xMzQxMUMgMTAuNDE0NSA3LjEzNDExIDMuNTU4NzIgNC4yNTc2IDAgMEMgMS4zMjUzOSAzLjgyMDQgMy43OTU1NiA3LjEzMDgxIDcuMDY4NiA5LjQ3MzAzQyAxMC4zNDE3IDExLjgxNTIgMTQuMjU1NyAxMy4wNzM0IDE4LjI2OSAxMy4wNzM0QyAyMi4yODIzIDEzLjA3MzQgMjYuMTk2MyAxMS44MTUyIDI5LjQ2OTQgOS40NzMwM0MgMzIuNzQyNCA3LjEzMDgxIDM1LjIxMjYgMy44MjA0IDM2LjUzOCAwQyAzMi45NzA1IDQuMjU3NiAyNi4xMTQ4IDcuMTM0MTEgMTguMjY0NiA3LjEzNDExWiIvPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjM5LjczIDIyODUuNDgpIiBkPSJNIDE4LjI3MzMgNS45MzkzMUMgMjYuMTIzNSA1LjkzOTMxIDMyLjk3OTMgOC44MTU4MyAzNi41MzggMTMuMDczNEMgMzUuMjEyNiA5LjI1MzAzIDMyLjc0MjQgNS45NDI2MiAyOS40Njk0IDMuNjAwNEMgMjYuMTk2MyAxLjI1ODE4IDIyLjI4MjMgMCAxOC4yNjkgMEMgMTQuMjU1NyAwIDEwLjM0MTcgMS4yNTgxOCA3LjA2ODYgMy42MDA0QyAzLjc5NTU2IDUuOTQyNjIgMS4zMjUzOSA5LjI1MzAzIDAgMTMuMDczNEMgMy41Njc0NSA4LjgyNDYzIDEwLjQyMzIgNS45MzkzMSAxOC4yNzMzIDUuOTM5MzFaIi8+CiAgICA8L2c+CiAgICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjY5LjMgMjI4MS4zMSkiIGQ9Ik0gNS44OTM1MyAyLjg0NEMgNS45MTg4OSAzLjQzMTY1IDUuNzcwODUgNC4wMTM2NyA1LjQ2ODE1IDQuNTE2NDVDIDUuMTY1NDUgNS4wMTkyMiA0LjcyMTY4IDUuNDIwMTUgNC4xOTI5OSA1LjY2ODUxQyAzLjY2NDMgNS45MTY4OCAzLjA3NDQ0IDYuMDAxNTEgMi40OTgwNSA1LjkxMTcxQyAxLjkyMTY2IDUuODIxOSAxLjM4NDYzIDUuNTYxNyAwLjk1NDg5OCA1LjE2NDAxQyAwLjUyNTE3IDQuNzY2MzMgMC4yMjIwNTYgNC4yNDkwMyAwLjA4MzkwMzcgMy42Nzc1N0MgLTAuMDU0MjQ4MyAzLjEwNjExIC0wLjAyMTIzIDIuNTA2MTcgMC4xNzg3ODEgMS45NTM2NEMgMC4zNzg3OTMgMS40MDExIDAuNzM2ODA5IDAuOTIwODE3IDEuMjA3NTQgMC41NzM1MzhDIDEuNjc4MjYgMC4yMjYyNTkgMi4yNDA1NSAwLjAyNzU5MTkgMi44MjMyNiAwLjAwMjY3MjI5QyAzLjYwMzg5IC0wLjAzMDcxMTUgNC4zNjU3MyAwLjI0OTc4OSA0Ljk0MTQyIDAuNzgyNTUxQyA1LjUxNzExIDEuMzE1MzEgNS44NTk1NiAyLjA1Njc2IDUuODkzNTMgMi44NDRaIi8+CiAgICAgIDxwYXRoIHRyYW5zZm9ybT0idHJhbnNsYXRlKDE2MzkuOCAyMzIzLjgxKSIgZD0iTSA3LjQyNzg5IDMuNTgzMzhDIDcuNDYwMDggNC4zMjQzIDcuMjczNTUgNS4wNTgxOSA2Ljg5MTkzIDUuNjkyMTNDIDYuNTEwMzEgNi4zMjYwNyA1Ljk1MDc1IDYuODMxNTYgNS4yODQxMSA3LjE0NDZDIDQuNjE3NDcgNy40NTc2MyAzLjg3MzcxIDcuNTY0MTQgMy4xNDcwMiA3LjQ1MDYzQyAyLjQyMDMyIDcuMzM3MTIgMS43NDMzNiA3LjAwODcgMS4yMDE4NCA2LjUwNjk1QyAwLjY2MDMyOCA2LjAwNTIgMC4yNzg2MSA1LjM1MjY4IDAuMTA1MDE3IDQuNjMyMDJDIC0wLjA2ODU3NTcgMy45MTEzNSAtMC4wMjYyMzYxIDMuMTU0OTQgMC4yMjY2NzUgMi40NTg1NkMgMC40Nzk1ODcgMS43NjIxNyAwLjkzMTY5NyAxLjE1NzEzIDEuNTI1NzYgMC43MjAwMzNDIDIuMTE5ODMgMC4yODI5MzUgMi44MjkxNCAwLjAzMzQzOTUgMy41NjM4OSAwLjAwMzEzMzQ0QyA0LjU0NjY3IC0wLjAzNzQwMzMgNS41MDUyOSAwLjMxNjcwNiA2LjIyOTYxIDAuOTg3ODM1QyA2Ljk1MzkzIDEuNjU4OTYgNy4zODQ4NCAyLjU5MjM1IDcuNDI3ODkgMy41ODMzOEwgNy40Mjc4OSAzLjU4MzM4WiIvPgogICAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxNjM4LjM2IDIyODYuMDYpIiBkPSJNIDIuMjc0NzEgNC4zOTYyOUMgMS44NDM2MyA0LjQxNTA4IDEuNDE2NzEgNC4zMDQ0NSAxLjA0Nzk5IDQuMDc4NDNDIDAuNjc5MjY4IDMuODUyNCAwLjM4NTMyOCAzLjUyMTE0IDAuMjAzMzcxIDMuMTI2NTZDIDAuMDIxNDEzNiAyLjczMTk4IC0wLjA0MDM3OTggMi4yOTE4MyAwLjAyNTgxMTYgMS44NjE4MUMgMC4wOTIwMDMxIDEuNDMxOCAwLjI4MzIwNCAxLjAzMTI2IDAuNTc1MjEzIDAuNzEwODgzQyAwLjg2NzIyMiAwLjM5MDUxIDEuMjQ2OTEgMC4xNjQ3MDggMS42NjYyMiAwLjA2MjA1OTJDIDIuMDg1NTMgLTAuMDQwNTg5NyAyLjUyNTYxIC0wLjAxNTQ3MTQgMi45MzA3NiAwLjEzNDIzNUMgMy4zMzU5MSAwLjI4Mzk0MSAzLjY4NzkyIDAuNTUxNTA1IDMuOTQyMjIgMC45MDMwNkMgNC4xOTY1MiAxLjI1NDYyIDQuMzQxNjkgMS42NzQzNiA0LjM1OTM1IDIuMTA5MTZDIDQuMzgyOTkgMi42OTEwNyA0LjE3Njc4IDMuMjU4NjkgMy43ODU5NyAzLjY4NzQ2QyAzLjM5NTE2IDQuMTE2MjQgMi44NTE2NiA0LjM3MTE2IDIuMjc0NzEgNC4zOTYyOUwgMi4yNzQ3MSA0LjM5NjI5WiIvPgogICAgPC9nPgogIDwvZz4+Cjwvc3ZnPgo=);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=59e786e0-0684-4c81-9e8b-5240a029c4c6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Tutorial_5_TrAdaBoost-02-April-2025">Tutorial_5_TrAdaBoost 02 April 2025<a class="anchor-link" href="#Tutorial_5_TrAdaBoost-02-April-2025">¶</a></h1><h2 id="Transfer-Learning-for-Class-AMAT-6000A:-Advanced-Materials-Informatics-Spring-2025,-HKUST-(GZ)">Transfer Learning for Class AMAT 6000A: Advanced Materials Informatics Spring 2025, HKUST (GZ)<a class="anchor-link" href="#Transfer-Learning-for-Class-AMAT-6000A:-Advanced-Materials-Informatics-Spring-2025,-HKUST-(GZ)">¶</a></h2><p>This tutorial introduces the concept and implementation of an instance transfer learning algorithm, <strong>TrAdaBoost</strong>, which is an extension of the AdaBoost algorithm. We will go step by step an example of utilizing TrAdaBoost for property classification, using Python and Jpyter Noebooks.</p>
<h2 id="Code-Example,-Data,-and-Illustrations">Code Example, Data, and Illustrations<a class="anchor-link" href="#Code-Example,-Data,-and-Illustrations">¶</a></h2><p>The codes and examples are provided by Bin CAO on <a href="https://github.com/Bin-Cao/TrAdaboost/tree/main/TrAdaBoost">https://github.com/Bin-Cao/TrAdaboost/tree/main/TrAdaBoost</a>.</p>
<h3 id="Preparing-for-the-Class">Preparing for the Class<a class="anchor-link" href="#Preparing-for-the-Class">¶</a></h3><p>To run the code examples in this tutorial, ensure you have Python and Jupyter Notebook installed. Below is a comprehensive guide to help you get set up</p>
<h3 id="Requirements">Requirements<a class="anchor-link" href="#Requirements">¶</a></h3><ul>
<li>python &gt;= 3.7</li>
<li>sklearn</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=18a2907a-0a3b-4ec7-865e-53dcafaa2b53">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Introduction-of-TrAdaBoost">Introduction of TrAdaBoost<a class="anchor-link" href="#Introduction-of-TrAdaBoost">¶</a></h2><p>TrAdaBoost (Transfer AdaBoost) is a transfer learning algorithm designed to improve the performance of machine learning models when the training data and test data come from different distributions. It is an extension of the AdaBoost algorithm, specifically tailored for transfer learning scenarios. TrAdaBoost aims to adapt the source data to the target domain by reweighting the samples in the source data based on their relevance to the target domain. The key idea is to iteratively reweight the training instances, giving more importance to instances that are harder to classify correctly, and to combine multiple weak learners to form a strong learner.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7ce7ae80-34d5-4f3c-a2e3-cd8d97876644">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Initialization-and-Setup">Initialization and Setup<a class="anchor-link" href="#Initialization-and-Setup">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=f796f54e-2d3d-4b85-a4e1-624388713e35">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [238]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=191cd370-36be-43f4-a31f-089976df676e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Function-Definition-and-Explanation">Function Definition and Explanation<a class="anchor-link" href="#Function-Definition-and-Explanation">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=be180132-78dc-42aa-a90d-a6e69604fd61">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [240]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">TrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Boosting for Transfer Learning.</span>

<span class="sd">    Please feel free to open issues in the Github : https://github.com/Bin-Cao/TrAdaboost</span>
<span class="sd">    or </span>
<span class="sd">    contact Bin Cao (bcao@shu.edu.cn)</span>
<span class="sd">    in case of any problems/comments/suggestions in using the code. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    trans_S : feature matrix of same-distribution training data</span>

<span class="sd">    trans_A : feature matrix of diff-distribution training data</span>

<span class="sd">    label_S : label of same-distribution training data, 0 or 1</span>

<span class="sd">    label_A : label of diff-distribution training data, 0 or 1</span>

<span class="sd">    test : feature matrix of test data</span>

<span class="sd">    N : int, default=20</span>
<span class="sd">    the number of weak estimators</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Dai, W., Yang, Q., et al. (2007). </span>
<span class="sd">    Boosting for Transfer Learning.(2007), 193--200. </span>
<span class="sd">    In Proceedings of the 24th international conference on Machine learning.</span>

<span class="sd">    .. [2] GitHub: https://github.com/chenchiwei/tradaboost/blob/master/TrAdaboost.py</span>
<span class="sd">    """</span>

    <span class="n">trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">label_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">row_A</span> <span class="o">=</span> <span class="n">trans_A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">row_S</span> <span class="o">=</span> <span class="n">trans_S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">row_T</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">N</span> <span class="o">&gt;</span> <span class="n">row_A</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'The maximum of iterations should be smaller than '</span><span class="p">,</span> <span class="n">row_A</span><span class="p">)</span>
        
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Initialize the weights</span>
    <span class="n">weights_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_A</span>
    <span class="n">weights_S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_S</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">weights_A</span><span class="p">,</span> <span class="n">weights_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 

    <span class="n">bata</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">row_A</span> <span class="o">/</span> <span class="n">N</span><span class="p">)))</span>

    <span class="c1"># Save prediction labels and bata_t</span>
    <span class="n">bata_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
    <span class="n">result_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span> <span class="o">+</span> <span class="n">row_T</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>

    <span class="c1"># Save the prediction labels of test data </span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">row_T</span><span class="p">])</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">'params initial finished.'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

    <span class="n">trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    <span class="n">trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">trans_label</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>

    <span class="n">error_rate_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">misclassify_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">calculate_P</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_classify</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
        <span class="n">error_rate</span><span class="p">,</span><span class="n">misclassify</span> <span class="o">=</span> <span class="n">calculate_error_rate</span><span class="p">(</span><span class="n">label_S</span><span class="p">,</span> <span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span><span class="n">weights</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">if</span> <span class="n">error_rate</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">error_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span> 
            <span class="c1"># for a binary classifier </span>
            <span class="c1"># reverse the prediction label 0 to 1; 1 to 0.</span>
            <span class="n">pre_labels</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
            <span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">pre_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span>
        <span class="c1"># Avoiding overfitting</span>
        <span class="k">elif</span> <span class="n">error_rate</span> <span class="o">&lt;=</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="n">N</span> <span class="o">=</span> <span class="n">i</span>
            <span class="k">break</span> 
        <span class="n">error_rate_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error_rate</span><span class="p">)</span>
        <span class="n">misclassify_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">misclassify</span><span class="p">)</span>
        <span class="n">bata_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">error_rate</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">)</span>
        <span class="nb">print</span> <span class="p">(</span><span class="s1">'Iter </span><span class="si">{}</span><span class="s1">-th result :'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="nb">print</span> <span class="p">(</span><span class="s1">'error rate :'</span><span class="p">,</span> <span class="n">error_rate</span><span class="p">,</span> <span class="s1">'|| bata_T :'</span><span class="p">,</span> <span class="n">error_rate</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
        <span class="c1"># Changing the data weights of same-distribution training data</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_S</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">bata_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">[</span><span class="n">j</span><span class="p">])))</span>
        <span class="c1"># Changing the data weights of diff-distribution training data</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_A</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">bata</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_A</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_T</span><span class="p">):</span>
        <span class="n">left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">N</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)):</span><span class="n">N</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">bata_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">N</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)):</span><span class="n">N</span><span class="p">]))</span>
        <span class="n">right</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">bata_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">N</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)):</span><span class="n">N</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">left</span> <span class="o">&gt;=</span> <span class="n">right</span><span class="p">:</span>
            <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"TrAdaBoost is done"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The prediction labels of test data are :'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">predict</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">error_rate_list</span><span class="p">),</span><span class="mi">3</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">misclassify_list</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_P</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_classify</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">"gini"</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="s1">'balanced'</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="s2">"log2"</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="s2">"best"</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">P</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_error_rate</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_H</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">misclassify</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">label_R</span> <span class="o">-</span> <span class="n">label_H</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">label_H</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">label_R</span> <span class="o">-</span> <span class="n">label_H</span><span class="p">))</span> <span class="p">,</span> <span class="n">misclassify</span><span class="p">,</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=247f02f9-afe9-4002-a2a9-9696e2db8209">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.-Parameters:">1. Parameters:<a class="anchor-link" href="#1.-Parameters:">¶</a></h3><ul>
<li><code>trans_S</code>: Feature matrix of the source domain training data.</li>
<li><code>trans_A</code>: Feature matrix of the auxiliary domain training data (different distribution).</li>
<li><code>label_S</code>: Labels of the source domain training data.</li>
<li><code>label_A</code>: Labels of the auxiliary domain training data.</li>
<li><code>test</code>: Feature matrix of the test data.</li>
<li><code>N</code>: Number of weak estimators (default is 20).</li>
</ul>
<h3 id="2.-Data-Concatenation">2. Data Concatenation<a class="anchor-link" href="#2.-Data-Concatenation">¶</a></h3><ul>
<li><strong>Purpose</strong>: Combines the source and auxiliary domain data into a single dataset for training.</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">label_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<h3 id="3.-Initialization-of-Weights">3. Initialization of Weights<a class="anchor-link" href="#3.-Initialization-of-Weights">¶</a></h3><ul>
<li>Initializes weights for each instance in the auxiliary and source domains. The weights are normalized to ensure they sum up to 1.</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">row_A</span> <span class="o">=</span> <span class="n">trans_A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">row_S</span> <span class="o">=</span> <span class="n">trans_S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">row_T</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">weights_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_A</span>
<span class="n">weights_S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_S</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">weights_A</span><span class="p">,</span> <span class="n">weights_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<h3 id="4.-Parameter-Initialization">4. Parameter Initialization<a class="anchor-link" href="#4.-Parameter-Initialization">¶</a></h3><ul>
<li><strong>Beta Calculation</strong>: <code>bata</code> is a parameter that controls the rate at which weights are updated for the auxiliary domain instances.</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">bata</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">row_A</span> <span class="o">/</span> <span class="n">N</span><span class="p">)))</span>
</pre></div>
<h3 id="5.-Training-Loop">5. Training Loop<a class="anchor-link" href="#5.-Training-Loop">¶</a></h3><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">calculate_P</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_classify</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
    <span class="n">error_rate</span><span class="p">,</span> <span class="n">misclassify</span> <span class="o">=</span> <span class="n">calculate_error_rate</span><span class="p">(</span><span class="n">label_S</span><span class="p">,</span> <span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">,</span> <span class="p">:])</span>
</pre></div>
<ul>
<li><strong>Iteration</strong>: The algorithm iterates <code>N</code> times, training a weak learner in each iteration.</li>
<li><strong>Weighted Sampling</strong>: <code>calculate_P(weights)</code> computes the probability distribution for sampling instances based on their weights.</li>
<li><strong>Training Weak Learner</strong>: <code>train_classify</code> trains a weak learner (e.g., a decision tree) on the weighted data.</li>
<li><strong>Error Calculation</strong>: <code>calculate_error_rate</code> computes the error rate of the weak learner on the source domain data.</li>
</ul>
<h3 id="6.-Error-Handling-and-Weight-Update">6. Error Handling and Weight Update<a class="anchor-link" href="#6.-Error-Handling-and-Weight-Update">¶</a></h3><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">error_rate</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">error_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span>
    <span class="n">pre_labels</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>
    <span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">pre_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span>
<span class="k">elif</span> <span class="n">error_rate</span> <span class="o">&lt;=</span> <span class="mf">1e-10</span><span class="p">:</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">break</span>
</pre></div>
<ul>
<li><strong>Error Handling</strong>: If the error rate is greater than 0.5, the prediction labels are inverted (since the weak learner is performing worse than random guessing).</li>
<li><strong>Early Stopping</strong>: If the error rate is extremely low (less than a threshold), the algorithm stops early to prevent overfitting.</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">bata_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">error_rate</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_S</span><span class="p">):</span>
    <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">bata_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">[</span><span class="n">j</span><span class="p">])))</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_A</span><span class="p">):</span>
    <span class="n">weights</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">bata</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_A</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
</pre></div>
<ul>
<li><strong>Beta Update</strong>: Updates the bata_T array, which stores the beta values for each iteration.</li>
<li><strong>Weight Update</strong>: Adjusts the weights of the source and auxiliary domain instances based on their prediction accuracy.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=92167eec-e62e-4a87-8b8e-29b848348f54">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Experiment">Experiment<a class="anchor-link" href="#Experiment">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=318c23f9-2a09-44c7-8b8e-e34c6c21f93c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.-Load-Data">1. Load Data<a class="anchor-link" href="#1.-Load-Data">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=cc4d3374-5af2-4f35-aa6e-e6fd88e5b308">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [244]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># same-distribution training data</span>
<span class="n">S_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'Sdata.csv'</span><span class="p">)</span>
<span class="c1"># diff-distribution training data</span>
<span class="n">A_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'Adata.csv'</span><span class="p">)</span>
<span class="c1"># test data</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'Tdata.csv'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fb19dce9-cd0c-426f-9a99-ff983e7d9f73">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="2.-Data-Inspection">2. Data Inspection<a class="anchor-link" href="#2.-Data-Inspection">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=512325b5-74ba-4134-a52d-c0bc850dd68f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [246]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Same-distribution training data: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">S_train_data</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Diff-distribution training data: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A_train_data</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Test data: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Same-distribution training data: 
     Sn   Bi   In   Ti  UTS(MPa)
0  90.1  3.5  1.8  0.1         0
1  93.8  0.5  0.8  0.4         0
2  94.1  0.5  0.8  0.1         0
3  92.1  0.5  2.8  0.1         0
4  88.8  3.5  2.8  0.4         1
5  89.1  3.5  2.8  0.1         1
6  91.1  3.5  0.8  0.1         1 

Diff-distribution training data: 
      Sn   Bi   In   Ti  UTS(MPa)
0   92.7  3.0  2.5  0.3         0
1   92.6  2.5  3.3  0.1         0
2   92.9  3.0  2.5  0.1         0
3   92.4  2.5  3.4  0.2         0
4   92.5  2.5  3.4  0.1         0
5   91.9  3.0  3.5  0.1         0
6   91.5  3.0  3.5  0.5         0
7   91.7  3.0  3.5  0.3         0
8   92.5  3.0  2.5  0.5         0
9   90.9  4.0  3.5  0.1         1
10  91.7  4.0  2.5  0.3         1
11  91.5  4.0  2.5  0.5         1
12  90.7  4.0  3.5  0.3         1
13  90.9  5.0  2.5  0.1         1
14  90.5  4.0  3.5  0.5         1
15  89.7  5.0  3.5  0.3         1
16  89.5  5.0  3.5  0.5         1
17  89.9  5.0  3.5  0.1         1
18  90.7  5.0  2.5  0.3         1
19  90.5  5.0  2.5  0.5         1 

Test data: 
     Ti   Bi   In  Ti.1  UTS(MPa)
0  91.8  0.5  2.8   0.4         0
1  93.1  0.5  1.8   0.1         0
2  90.6  2.0  2.8   0.1         0
3  89.8  3.5  1.8   0.4         1
4  90.8  3.5  0.8   0.4         1 

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e29981e5-0180-4399-9922-e6971c296e44">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="3.-Transfer-Learning-and-Prediction">3. Transfer Learning and Prediction<a class="anchor-link" href="#3.-Transfer-Learning-and-Prediction">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=d4a9bd08-14a8-4771-b732-3dabc09de0d8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [248]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trans_S</span> <span class="o">=</span> <span class="n">S_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">trans_A</span> <span class="o">=</span> <span class="n">A_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">label_S</span> <span class="o">=</span> <span class="n">S_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">label_A</span> <span class="o">=</span> <span class="n">A_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">pre</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">TrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">label_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Ground truth: "</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">label_S</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
Ground truth:  [0 0 0 0 1 1 1]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8ae4d740-82eb-418b-8f96-e47979fe0df8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="4.-Visualization">4. Visualization<a class="anchor-link" href="#4.-Visualization">¶</a></h3><p>To illustrate how prediction errors change with iteration number, we test the first 20 iterations.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=3eda20a5-427c-4132-a791-ef50b395991e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [250]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">"""</span>
<span class="sd"># example of book</span>
<span class="sd"># [an introduction of materials informatics II, Tong-yi Zhang]</span>
<span class="sd">"""</span>

<span class="n">N_iter</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">pre_err</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_iter</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">pre</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">TrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">label_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">pre_err</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">pre</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">trans_S</span><span class="p">))</span>

<span class="n">_</span><span class="p">,</span><span class="n">error</span><span class="p">,</span><span class="n">misclassify_list</span> <span class="o">=</span> <span class="n">TrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 0.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[1. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[1. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 0. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 0. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 0. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 0. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
Iter 15-th result :
error rate : 0.19080105633802824 || bata_T : 0.23579004623334252
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
Iter 15-th result :
error rate : 0.19080105633802824 || bata_T : 0.23579004623334252
------------------------------------------------------------
Iter 16-th result :
error rate : 0.1908711812165715 || bata_T : 0.23589714861912503
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
Iter 15-th result :
error rate : 0.19080105633802824 || bata_T : 0.23579004623334252
------------------------------------------------------------
Iter 16-th result :
error rate : 0.1908711812165715 || bata_T : 0.23589714861912503
------------------------------------------------------------
Iter 17-th result :
error rate : 0.19091367430396053 || bata_T : 0.23596205774423593
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
Iter 15-th result :
error rate : 0.19080105633802824 || bata_T : 0.23579004623334252
------------------------------------------------------------
Iter 16-th result :
error rate : 0.1908711812165715 || bata_T : 0.23589714861912503
------------------------------------------------------------
Iter 17-th result :
error rate : 0.19091367430396053 || bata_T : 0.23596205774423593
------------------------------------------------------------
Iter 18-th result :
error rate : 0.19094024787094088 || bata_T : 0.23600265291713904
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
Iter 15-th result :
error rate : 0.19080105633802824 || bata_T : 0.23579004623334252
------------------------------------------------------------
Iter 16-th result :
error rate : 0.1908711812165715 || bata_T : 0.23589714861912503
------------------------------------------------------------
Iter 17-th result :
error rate : 0.19091367430396053 || bata_T : 0.23596205774423593
------------------------------------------------------------
Iter 18-th result :
error rate : 0.19094024787094088 || bata_T : 0.23600265291713904
------------------------------------------------------------
Iter 19-th result :
error rate : 0.1909565477846002 || bata_T : 0.2360275548386243
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 0. 1. 1. 1.]
params initial finished.
============================================================
Iter 0-th result :
error rate : 0.14285714285714288 || bata_T : 0.1666666666666667
------------------------------------------------------------
Iter 1-th result :
error rate : 0.08333333333333334 || bata_T : 0.09090909090909093
------------------------------------------------------------
Iter 2-th result :
error rate : 0.2727272727272727 || bata_T : 0.37499999999999994
------------------------------------------------------------
Iter 3-th result :
error rate : 0.03125000000000001 || bata_T : 0.03225806451612904
------------------------------------------------------------
Iter 4-th result :
error rate : 0.17741935483870971 || bata_T : 0.215686274509804
------------------------------------------------------------
Iter 5-th result :
error rate : 0.15686274509803924 || bata_T : 0.186046511627907
------------------------------------------------------------
Iter 6-th result :
error rate : 0.1802325581395349 || bata_T : 0.2198581560283688
------------------------------------------------------------
Iter 7-th result :
error rate : 0.18085106382978722 || bata_T : 0.22077922077922074
------------------------------------------------------------
Iter 8-th result :
error rate : 0.18614718614718612 || bata_T : 0.22872340425531912
------------------------------------------------------------
Iter 9-th result :
error rate : 0.18749999999999994 || bata_T : 0.2307692307692307
------------------------------------------------------------
Iter 10-th result :
error rate : 0.18903436988543365 || bata_T : 0.2330978809283551
------------------------------------------------------------
Iter 11-th result :
error rate : 0.18970736629667 || bata_T : 0.2341220423412204
------------------------------------------------------------
Iter 12-th result :
error rate : 0.19022415940224158 || bata_T : 0.2349096501345636
------------------------------------------------------------
Iter 13-th result :
error rate : 0.19050365244136874 || bata_T : 0.23533602469722165
------------------------------------------------------------
Iter 14-th result :
error rate : 0.19069104725718364 || bata_T : 0.23562206572769964
------------------------------------------------------------
Iter 15-th result :
error rate : 0.19080105633802824 || bata_T : 0.23579004623334252
------------------------------------------------------------
Iter 16-th result :
error rate : 0.1908711812165715 || bata_T : 0.23589714861912503
------------------------------------------------------------
Iter 17-th result :
error rate : 0.19091367430396053 || bata_T : 0.23596205774423593
------------------------------------------------------------
Iter 18-th result :
error rate : 0.19094024787094088 || bata_T : 0.23600265291713904
------------------------------------------------------------
Iter 19-th result :
error rate : 0.1909565477846002 || bata_T : 0.2360275548386243
------------------------------------------------------------
TrAdaBoost is done
============================================================
The prediction labels of test data are :
[0. 0. 0. 1. 1.]
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=ff97b483-a43a-4b3d-8014-8f3a6f948667">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [251]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span><span class="n">misclassify_list</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">19</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s1">'the N-th classifier'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span><span class="n">pre_err</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">19</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"k"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s1">'TrAdaBoost'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'error rate'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'iterations'</span><span class="p">)</span>


<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span><span class="n">error</span><span class="p">[</span><span class="mi">5</span><span class="p">:</span><span class="mi">19</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"b"</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">'weighted error rate'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'weighted error rate'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Same'</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.16</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'iteration number.png'</span><span class="p">,</span><span class="n">bbox_inches</span> <span class="o">=</span> <span class="s1">'tight'</span><span class="p">,</span><span class="n">dpi</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8f9b46a6-983a-4004-ae27-26ed6ec540d3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Summary-of-TrAdaBoost">Summary of TrAdaBoost<a class="anchor-link" href="#Summary-of-TrAdaBoost">¶</a></h2><h3 id="Advantages"><strong>Advantages</strong><a class="anchor-link" href="#Advantages">¶</a></h3><ul>
<li><strong>Adaptability</strong>: It effectively uses source domain data to enhance the performance of the target domain model, especially when target domain data is limited.</li>
<li><strong>Flexibility</strong>: It can handle source and target domains with different data distributions.</li>
<li><strong>Robustness</strong>: By adjusting sample weights, it reduces the impact of irrelevant source data on the target domain model.</li>
</ul>
<h3 id="Disadvantages"><strong>Disadvantages</strong><a class="anchor-link" href="#Disadvantages">¶</a></h3><ul>
<li><strong>Risk of negative transfer</strong>: If the source and target domains are not strongly related, it may lead to negative transfer, where source data negatively impacts the target domain model.</li>
<li><strong>Computational complexity</strong>: It requires processing both source and target domain data, increasing computational complexity.</li>
<li><strong>Parameter selection</strong>: Careful tuning of parameters such as the number of iterations and initial weights is necessary to ensure good model performance.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fdd992e0-b814-43c3-a09c-9227102da147">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Introduction-of-MultiSource-TrAdaBoost">Introduction of MultiSource-TrAdaBoost<a class="anchor-link" href="#Introduction-of-MultiSource-TrAdaBoost">¶</a></h2><p><strong>MultiSource-TrAdaBoost</strong> is an extension of the TrAdaBoost algorithm designed to handle transfer learning scenarios where multiple source domains are available. While TrAdaBoost focuses on transferring knowledge from a single source domain to a target domain, MultiSource-TrAdaBoost leverages multiple source domains to improve the learning process in the target domain. This makes it particularly useful when there are several source domains that may collectively provide more comprehensive information than a single source domain.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bd22577a-dbee-479a-9733-ef5edbd6e10c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Function-Definition-and-Explanation">Function Definition and Explanation<a class="anchor-link" href="#Function-Definition-and-Explanation">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e3024c69-1b2f-454c-b0c7-053cb905d5ca">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [255]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">MultiSourceTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Boosting for MultiSource Transfer Learning.</span>

<span class="sd">    Please feel free to open issues in the Github : https://github.com/Bin-Cao/TrAdaboost</span>
<span class="sd">    or </span>
<span class="sd">    contact Bin Cao (bcao@shu.edu.cn)</span>
<span class="sd">    in case of any problems/comments/suggestions in using the code. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    trans_S : feature matrix of same-distribution training data</span>

<span class="sd">    Multi_trans_A : dict, feature matrix of diff-distribution training data</span>
<span class="sd">    e.g.,</span>
<span class="sd">    Multi_trans_A = {</span>
<span class="sd">    'trans_A_1' :  data_1 , </span>
<span class="sd">    'trans_A_2' : data_2 ,</span>
<span class="sd">    ......</span>
<span class="sd">    }</span>
<span class="sd">    data_1 : feature matrix of diff-distribution training dataset 1</span>
<span class="sd">    data_2 : feature matrix of diff-distribution training dataset 2</span>

<span class="sd">    label_S : label of same-distribution training data, -1 or 1</span>

<span class="sd">    Multi_label_A : dict, label of diff-distribution training data, -1 or 1</span>
<span class="sd">    e.g.,</span>
<span class="sd">    Multi_label_A = {</span>
<span class="sd">    'label_A_1' :  label_1 , </span>
<span class="sd">    'label_A_2' : label_2 ,</span>
<span class="sd">    ......</span>
<span class="sd">    }</span>
<span class="sd">    label_1 : label of diff-distribution training dataset 1, -1 or 1</span>
<span class="sd">    label_1 : label of diff-distribution training dataset 2, -1 or 1</span>

<span class="sd">    test : feature matrix of test data</span>

<span class="sd">    N : int, default=20</span>
<span class="sd">    the number of weak estimators</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Yao, Y., &amp; Doretto, G. (2010, June)</span>
<span class="sd">    Boosting for transfer learning with multiple sources. IEEE.</span>
<span class="sd">    DOI: 10.1109/CVPR.2010.5539857</span>

<span class="sd">    """</span>
    <span class="c1"># prepare trans_A</span>
    <span class="n">trans_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">trans_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_A</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">p</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># prepare label_A</span>
    <span class="n">label_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">pass</span> 
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">label_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">label_A</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">p</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
   
    <span class="n">trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">label_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">row_A</span> <span class="o">=</span> <span class="n">trans_A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">row_S</span> <span class="o">=</span> <span class="n">trans_S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">row_T</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="n">row_A</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'The maximum of iterations should be smaller than '</span><span class="p">,</span> <span class="n">row_A</span><span class="p">)</span>

    <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Initialize the weights</span>
    <span class="n">weights_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_A</span>
    <span class="n">weights_S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_S</span>
    <span class="c1"># one-dim column in the shape of ((row_A+row_S),1), column vector</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">weights_A</span><span class="p">,</span> <span class="n">weights_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 

    <span class="n">alpha_S</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">row_A</span> <span class="o">/</span> <span class="n">N</span><span class="p">))))</span>

    <span class="c1"># Save prediction labels and bata_t</span>
    <span class="n">alpha_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
    <span class="n">result_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span> <span class="o">+</span> <span class="n">row_T</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
    <span class="c1"># output label</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">row_T</span><span class="p">])</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">'params initial finished.'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

    <span class="n">trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    <span class="n">trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">trans_label</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>

    <span class="n">error_rate_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">error_rate</span> <span class="p">,</span> <span class="n">Source_index</span><span class="p">,</span> <span class="n">start</span> <span class="o">=</span> <span class="n">Multi_train_classifier</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span><span class="n">row_A</span><span class="p">,</span><span class="n">row_S</span><span class="p">)</span>
        
        <span class="c1"># Avoiding overfitting</span>
        <span class="k">if</span> <span class="n">error_rate</span> <span class="o">&lt;=</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="n">N</span> <span class="o">=</span> <span class="n">i</span>
            <span class="k">break</span>  

        <span class="n">error_rate_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error_rate</span><span class="p">)</span>
        <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_rate</span><span class="p">)</span> 
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Iter </span><span class="si">{}</span><span class="s1">-th result :'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'The </span><span class="si">{}</span><span class="s1">-th diff-distribution training dataset is chosen to transfer'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">Source_index</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'error rate :'</span><span class="p">,</span> <span class="n">error_rate</span><span class="p">,</span> <span class="s1">'|| alpha_T :'</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_rate</span><span class="p">)</span> <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

        <span class="c1"># Changing the data weights of same-distribution training data</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_S</span><span class="p">):</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
        <span class="c1"># Changing the data weights of diff-distribution training data</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">Source_index</span><span class="p">])</span> <span class="p">):</span>
            <span class="n">loc</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">j</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">loc</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">loc</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">alpha_S</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">loc</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_A</span><span class="p">[</span><span class="n">loc</span><span class="p">]))</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_T</span><span class="p">):</span>
        <span class="n">res_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">if</span> <span class="n">res_</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"MultiSourceTrAdaBoost is done"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The prediction labels of test data are :'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">predict</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">error_rate_list</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_classifier</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">ratio_weight</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">"gini"</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="s2">"log2"</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="s2">"best"</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">ratio_weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">Multi_train_classifier</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">,</span><span class="n">label_S</span><span class="p">,</span> <span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span><span class="n">row_A</span><span class="p">,</span><span class="n">row_S</span><span class="p">):</span>
    <span class="n">_result_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)])</span>
    <span class="n">error_record</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">start_record</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)):</span>
        <span class="n">start_record</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
        <span class="n">sub_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">item</span><span class="p">]</span>
        <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sub_dataset</span><span class="p">)</span>
        <span class="c1"># train a classifier with the 'item'-th data source</span>
        <span class="n">_trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_data</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">data_dim</span><span class="p">],</span> <span class="n">trans_data</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
        <span class="n">_trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_label</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">data_dim</span><span class="p">],</span> <span class="n">trans_label</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
        <span class="n">_ratio_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">weights</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">data_dim</span><span class="p">],</span> <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
        <span class="n">_result_label</span><span class="p">[:,</span> <span class="n">item</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_classifier</span><span class="p">(</span><span class="n">_trans_data</span><span class="p">,</span> <span class="n">_trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">_ratio_weight</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">+=</span> <span class="n">data_dim</span>
        <span class="c1"># cal error rate </span>
        <span class="n">_error_rate</span> <span class="o">=</span> <span class="n">calculate_error_rate</span><span class="p">(</span><span class="n">label_S</span><span class="p">,</span> <span class="n">_result_label</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">,</span> <span class="n">item</span><span class="p">],</span><span class="n">weights</span><span class="p">[</span><span class="n">row_A</span><span class="p">:</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">if</span> <span class="n">_error_rate</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">_error_rate</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">_error_rate</span> 
            <span class="c1"># for a binary classifier </span>
            <span class="c1"># reverse the prediction label -1 to 1; 1 to -1.</span>
            <span class="n">pre_labels</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">_result_label</span><span class="p">[:,</span> <span class="n">item</span><span class="p">])</span>
            <span class="n">_result_label</span><span class="p">[:,</span> <span class="n">item</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">pre_labels</span>     
        <span class="n">error_record</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_error_rate</span><span class="p">)</span>
    <span class="n">error_record</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">error_record</span><span class="p">)</span>
    <span class="c1"># choise the best classifier</span>
    <span class="n">classifier_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">error_record</span> <span class="o">==</span> <span class="n">error_record</span><span class="o">.</span><span class="n">min</span><span class="p">()))</span>
    <span class="k">return</span> <span class="n">_result_label</span><span class="p">[:,</span><span class="n">classifier_index</span><span class="p">],</span> <span class="n">error_record</span><span class="p">[</span><span class="n">classifier_index</span><span class="p">],</span> <span class="n">classifier_index</span><span class="p">,</span><span class="n">start_record</span><span class="p">[</span><span class="n">classifier_index</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">calculate_error_rate</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_P</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="n">sign</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_P</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sign</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_P</span><span class="p">):</span>
    <span class="n">_res</span> <span class="o">=</span> <span class="n">label_R</span> <span class="o">-</span> <span class="n">label_P</span> 
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_R</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">_res</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">_res</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">_res</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=571b3dd6-5102-4915-925c-3464a65c0d51">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.-Parameters">1. Parameters<a class="anchor-link" href="#1.-Parameters">¶</a></h3><ul>
<li><code>trans_S</code>: Feature matrix of the target domain training data.</li>
<li><code>Multi_trans_A</code>: Dictionary of feature matrices of multiple source domain training data.</li>
<li><code>label_S</code>: Labels of the target domain training data.</li>
<li><code>Multi_label_A</code>: Dictionary of labels of multiple source domain training data.</li>
<li><code>test</code>: Feature matrix of the test data.</li>
<li><code>N</code>: Number of weak estimators (iterations).</li>
</ul>
<h3 id="2.-Prepare-Data">2. Prepare Data<a class="anchor-link" href="#2.-Prepare-Data">¶</a></h3><p>Combine the feature matrices and labels from all source domains into a single array.</p>
<div class="highlight"><pre><span></span><span class="n">trans_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">trans_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_A</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">p</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Prepare label_A</span>
<span class="n">label_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">label_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">label_A</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">p</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Combine source and target domain data</span>
<span class="n">trans_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">trans_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">label_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<h3 id="3.-Initialize-Weights">3. Initialize Weights<a class="anchor-link" href="#3.-Initialize-Weights">¶</a></h3><p>Assign equal weights to all data points in the source and target domains.</p>
<div class="highlight"><pre><span></span><span class="n">row_A</span> <span class="o">=</span> <span class="n">trans_A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">row_S</span> <span class="o">=</span> <span class="n">trans_S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">row_T</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Initialize weights</span>
<span class="n">weights_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_A</span>
<span class="n">weights_S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_S</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">weights_A</span><span class="p">,</span> <span class="n">weights_S</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
<h3 id="4.-Iterative-Training">4. Iterative Training<a class="anchor-link" href="#4.-Iterative-Training">¶</a></h3><p>Train weak classifiers iteratively, updating weights based on classifier performance.</p>
<div class="highlight"><pre><span></span><span class="n">alpha_S</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">row_A</span> <span class="o">/</span> <span class="n">N</span><span class="p">))))</span>
<span class="n">alpha_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
<span class="n">result_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span> <span class="o">+</span> <span class="n">row_T</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
<span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">row_T</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">result_label</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">error_rate</span><span class="p">,</span> <span class="n">Source_index</span><span class="p">,</span> <span class="n">start</span> <span class="o">=</span> <span class="n">Multi_train_classifier</span><span class="p">(</span>
        <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">trans_data</span><span class="p">,</span> <span class="n">trans_label</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">row_A</span><span class="p">,</span> <span class="n">row_S</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">error_rate</span> <span class="o">&lt;=</span> <span class="mf">1e-10</span><span class="p">:</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">i</span>
        <span class="k">break</span>
    <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">)</span> <span class="o">/</span> <span class="n">error_rate</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_S</span><span class="p">):</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">Source_index</span><span class="p">])):</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="n">j</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">loc</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">loc</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">alpha_S</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">loc</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">label_A</span><span class="p">[</span><span class="n">loc</span><span class="p">]))</span>
</pre></div>
<h3 id="5.-Combine-Predictions">5. Combine Predictions<a class="anchor-link" href="#5.-Combine-Predictions">¶</a></h3><p>Combine predictions from all classifiers to make final predictions on the test data.</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_T</span><span class="p">):</span>
    <span class="n">res_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_A</span> <span class="o">+</span> <span class="n">row_S</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">if</span> <span class="n">res_</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="k">return</span> <span class="n">predict</span>
</pre></div>
<h3 id="6.-Define-Multi_train_classifier-and-other-helper-functions">6. Define Multi_train_classifier and other helper functions<a class="anchor-link" href="#6.-Define-Multi_train_classifier-and-other-helper-functions">¶</a></h3>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=902356ee-ac99-4535-8a79-01c4bd22483b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Experiment">Experiment<a class="anchor-link" href="#Experiment">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a4525eda-ab8e-49df-8579-c0ff8f49284b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.-Load-Data">1. Load Data<a class="anchor-link" href="#1.-Load-Data">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6537e57a-9321-4c48-9e56-85feba35ab58">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [259]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># same-distribution training data</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Sdata.csv'</span><span class="p">)</span>
<span class="c1"># two diff-distribution training data</span>
<span class="n">A1_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Adata1.csv'</span><span class="p">)</span>
<span class="n">A2_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Adata2.csv'</span><span class="p">)</span>
<span class="c1"># test data</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Tdata.csv'</span><span class="p">)</span>

<span class="n">Multi_trans_A</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">'trans_A_1'</span> <span class="p">:</span> <span class="n">A1_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
<span class="s1">'trans_A_2'</span> <span class="p">:</span> <span class="n">A2_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">Multi_label_A</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">'label_A_1'</span> <span class="p">:</span>  <span class="n">A1_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> 
<span class="s1">'label_A_2'</span> <span class="p">:</span>  <span class="n">A2_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span>
<span class="p">}</span>
<span class="n">trans_S</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">label_S</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=166ec63d-aef7-4390-b2d8-efb9327c1776">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="2.-Data-Inspection">2. Data Inspection<a class="anchor-link" href="#2.-Data-Inspection">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=ba6c9eeb-c146-462c-aa92-57fd51dd3ec8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [261]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Multi_trans_A: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Multi_label_A: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"trans_S: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"label_S: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">label_S</span><span class="p">,</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"test: "</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Multi_trans_A: 
{'trans_A_1':         Cr       1/T     ln(t)    DO
0   10.380  0.001293  4.605170  8000
1   10.380  0.001293  5.521461  8000
2   10.380  0.001293  6.214608  8000
3   10.380  0.001293  6.907755  8000
4   11.022  0.001083  5.298317     0
5   11.022  0.001083  5.991465     0
6   11.022  0.001083  6.684612     0
7   11.022  0.001083  6.396930     0
8   11.022  0.001083  6.907755     0
9   11.160  0.001293  4.605170  8000
10  11.160  0.001293  5.521461  8000
11  11.160  0.001293  6.214608  8000
12  11.160  0.001293  6.907755  8000
13  11.430  0.001293  4.605170  8000
14  11.430  0.001293  5.521461  8000
15  11.430  0.001293  6.214608  8000
16  11.430  0.001293  6.907755  8000
17  11.810  0.001293  4.605170  8000
18  11.810  0.001293  5.521461  8000
19  11.810  0.001293  6.214608  8000
20  11.810  0.001293  6.907755  8000, 'trans_A_2':          Cr       1/T     ln(t)    DO
0   12.9510  0.001215  5.298317   200
1   12.9510  0.001215  5.991465   200
2   12.9510  0.001215  6.396930   200
3   12.9510  0.001215  6.684612   200
4   12.9510  0.001215  6.907755   200
5   14.1100  0.001293  4.605170  8000
6   14.1100  0.001293  5.521461  8000
7   14.1100  0.001293  6.214608  8000
8   14.1100  0.001293  6.907755  8000
9   16.7300  0.001293  5.298317     0
10  16.7300  0.001293  5.991465     0
11  16.7300  0.001293  6.396930     0
12  16.7300  0.001293  6.684612     0
13  16.7300  0.001293  6.907755     0
14  17.0882  0.001215  4.700480     0
15  17.0882  0.001215  5.298317   100
16  17.0882  0.001215  6.131226     0
17  17.0882  0.001215  6.396930     0
18  17.0882  0.001215  5.298317   300
19  17.0882  0.001215  5.991465   100
20  17.0882  0.001215  6.659294     0
21  17.0882  0.001215  5.991465   300
22  17.0882  0.001215  6.907755     0
23  17.0882  0.001215  6.396930   100
24  17.0882  0.001215  5.298317  2000
25  17.0882  0.001215  6.684612   100
26  17.0882  0.001215  6.907755   100
27  17.0882  0.001215  6.396930   300
28  17.0882  0.001215  5.991465  2000} 

Multi_label_A: 
{'label_A_1': 0    -1
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9    -1
10    1
11    1
12    1
13   -1
14    1
15    1
16    1
17   -1
18    1
19    1
20    1
Name: weightgain, dtype: int64, 'label_A_2': 0     1
1     1
2     1
3     1
4     1
5    -1
6     1
7     1
8     1
9    -1
10   -1
11   -1
12   -1
13   -1
14   -1
15   -1
16   -1
17   -1
18   -1
19   -1
20   -1
21   -1
22   -1
23    1
24    1
25    1
26    1
27    1
28    1
Name: weightgain, dtype: int64} 

trans_S: 
         Cr       1/T     ln(t)  DO
0   17.2690  0.001293  5.298317   8
1   17.2690  0.001293  5.598422   8
2   17.2690  0.001293  6.214608   8
3   17.2690  0.001293  5.940171   8
4   17.2690  0.001215  6.214608   8
5   17.2690  0.001215  4.605170   8
6   18.0596  0.001293  6.907755  10
7   18.0596  0.001293  7.170120  10
8   18.0596  0.001293  7.600902  10
9   18.0596  0.001145  5.768321  25
10  18.0596  0.001145  6.445720  25
11  18.0596  0.001145  6.907755  25
12  18.2693  0.001486  5.541264   8
13  18.2693  0.001486  3.688879   8
14  18.2693  0.001486  6.214608   8
15  18.2693  0.001486  6.363028   8
16  18.2693  0.001293  6.214608   8 

label_S: 
0    -1
1    -1
2    -1
3    -1
4     1
5     1
6    -1
7    -1
8     1
9     1
10    1
11    1
12   -1
13   -1
14   -1
15   -1
16   -1
Name: weightgain, dtype: int64 

test: 
        Cr       1/T     ln(t)  DO
0  17.2690  0.001215  5.298317   8
1  17.2690  0.001215  5.736572   8
2  17.2690  0.001215  5.991465   8
3  18.0596  0.001293  5.857933  10
4  18.0596  0.001293  3.401197  25
5  18.0596  0.001293  6.522093  10
6  18.0596  0.001293  5.768321  25
7  18.0596  0.001293  6.445720  25
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c0321985-7fc1-4106-bb16-be0d06c638c7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="3.-Prediction">3. Prediction<a class="anchor-link" href="#3.-Prediction">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=6dfc8966-384a-4bba-951f-861630d4d86e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [263]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">MultiSourceTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N</span><span class="p">,)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[ 1.  1.  1. -1. -1. -1. -1. -1.]
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[263]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(array([ 1.,  1.,  1., -1., -1., -1., -1., -1.]),
 array([0.059, 0.125, 0.25 , 0.19 ]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e4ea9520-2f73-4aba-9147-c7df56b50ce7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="4.-Visualization">4. Visualization<a class="anchor-link" href="#4.-Visualization">¶</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=31303321-9409-4523-9149-b55607212d6c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [265]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">N_iter</span> <span class="o">=</span> <span class="mi">21</span>
<span class="n">pre_err</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_iter</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">pre</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">MultiSourceTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">pre_err</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">pre</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">trans_S</span><span class="p">))</span>

<span class="n">pred</span><span class="p">,</span> <span class="n">error</span> <span class="o">=</span> <span class="n">MultiSourceTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117648 || alpha_T : 0.4028125819933177
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595744 || alpha_T : 0.2839920188029698
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595745 || alpha_T : 0.28399201880296965
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117648 || alpha_T : 0.4028125819933177
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595744 || alpha_T : 0.2839920188029698
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3916666666666666 || alpha_T : 0.2201559197191664
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.36170212765957444 || alpha_T : 0.2839920188029697
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3916666666666667 || alpha_T : 0.22015591971916618
------------------------------------------------------------
Iter 7-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.41095890410958913 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117648 || alpha_T : 0.4028125819933177
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595745 || alpha_T : 0.28399201880296965
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.410958904109589 || alpha_T : 0.1800013670157036
------------------------------------------------------------
Iter 8-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434344 || alpha_T : 0.1320757875207932
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.25000000000000006 || alpha_T : 0.5493061443340548
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595745 || alpha_T : 0.28399201880296965
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3916666666666666 || alpha_T : 0.2201559197191664
------------------------------------------------------------
Iter 7-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.410958904109589 || alpha_T : 0.1800013670157036
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.42441860465116277 || alpha_T : 0.15233020449309942
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434345 || alpha_T : 0.1320757875207931
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44196428571428575 || alpha_T : 0.11659694358385547
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.1904761904761905 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.36170212765957444 || alpha_T : 0.2839920188029697
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3916666666666667 || alpha_T : 0.22015591971916618
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.43434343434343436 || alpha_T : 0.13207578752079335
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142857 || alpha_T : 0.11659694358385565
------------------------------------------------------------
Iter 11-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44799999999999995 || alpha_T : 0.10437740693105518
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117648 || alpha_T : 0.4028125819933177
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595745 || alpha_T : 0.28399201880296965
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.42441860465116277 || alpha_T : 0.15233020449309942
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434343 || alpha_T : 0.13207578752079352
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142857 || alpha_T : 0.11659694358385565
------------------------------------------------------------
Iter 11-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.448 || alpha_T : 0.1043774069310551
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4528985507246377 || alpha_T : 0.09448304975631158
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595744 || alpha_T : 0.2839920188029698
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3916666666666666 || alpha_T : 0.2201559197191664
------------------------------------------------------------
Iter 7-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.41095890410958896 || alpha_T : 0.18000136701570377
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.42441860465116266 || alpha_T : 0.15233020449309967
------------------------------------------------------------
Iter 9-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434343 || alpha_T : 0.13207578752079352
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44196428571428575 || alpha_T : 0.11659694358385547
------------------------------------------------------------
Iter 11-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.44800000000000006 || alpha_T : 0.10437740693105492
------------------------------------------------------------
Iter 12-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.45289855072463775 || alpha_T : 0.0944830497563115
------------------------------------------------------------
Iter 13-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.45695364238410596 || alpha_T : 0.08630637133349685
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619047 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.36170212765957444 || alpha_T : 0.2839920188029697
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.43434343434343436 || alpha_T : 0.13207578752079335
------------------------------------------------------------
Iter 10-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142857 || alpha_T : 0.11659694358385565
------------------------------------------------------------
Iter 11-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44799999999999995 || alpha_T : 0.10437740693105518
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4528985507246377 || alpha_T : 0.09448304975631158
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.456953642384106 || alpha_T : 0.08630637133349665
------------------------------------------------------------
Iter 14-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46036585365853666 || alpha_T : 0.07943494787945221
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117648 || alpha_T : 0.4028125819933177
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595745 || alpha_T : 0.28399201880296965
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.410958904109589 || alpha_T : 0.1800013670157036
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.42441860465116277 || alpha_T : 0.15233020449309942
------------------------------------------------------------
Iter 9-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434343 || alpha_T : 0.13207578752079352
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142857 || alpha_T : 0.11659694358385565
------------------------------------------------------------
Iter 11-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.448 || alpha_T : 0.1043774069310551
------------------------------------------------------------
Iter 12-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4528985507246377 || alpha_T : 0.09448304975631158
------------------------------------------------------------
Iter 13-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4569536423841061 || alpha_T : 0.08630637133349665
------------------------------------------------------------
Iter 14-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46036585365853666 || alpha_T : 0.07943494787945221
------------------------------------------------------------
Iter 15-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46327683615819215 || alpha_T : 0.07357882216814372
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.36170212765957444 || alpha_T : 0.2839920188029697
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511629 || alpha_T : 0.1523302044930992
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.43434343434343436 || alpha_T : 0.13207578752079335
------------------------------------------------------------
Iter 10-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.44196428571428564 || alpha_T : 0.11659694358385583
------------------------------------------------------------
Iter 11-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44799999999999984 || alpha_T : 0.10437740693105536
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4528985507246377 || alpha_T : 0.09448304975631158
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.45695364238410596 || alpha_T : 0.08630637133349685
------------------------------------------------------------
Iter 14-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4603658536585366 || alpha_T : 0.07943494787945231
------------------------------------------------------------
Iter 15-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4632768361581922 || alpha_T : 0.07357882216814354
------------------------------------------------------------
Iter 16-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4657894736842106 || alpha_T : 0.06852812323397899
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.1904761904761905 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.36170212765957444 || alpha_T : 0.2839920188029697
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.3916666666666667 || alpha_T : 0.22015591971916618
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.41095890410958913 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.43434343434343436 || alpha_T : 0.13207578752079335
------------------------------------------------------------
Iter 10-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.44196428571428564 || alpha_T : 0.11659694358385583
------------------------------------------------------------
Iter 11-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4479999999999999 || alpha_T : 0.10437740693105518
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.45289855072463775 || alpha_T : 0.0944830497563115
------------------------------------------------------------
Iter 13-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4569536423841059 || alpha_T : 0.08630637133349703
------------------------------------------------------------
Iter 14-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46036585365853655 || alpha_T : 0.0794349478794525
------------------------------------------------------------
Iter 15-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46327683615819204 || alpha_T : 0.07357882216814392
------------------------------------------------------------
Iter 16-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4657894736842105 || alpha_T : 0.06852812323397918
------------------------------------------------------------
Iter 17-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4679802955665025 || alpha_T : 0.06412716776183942
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.125 || alpha_T : 0.9729550745276566
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619044 || alpha_T : 0.7234594914681628
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3088235294117647 || alpha_T : 0.4028125819933178
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.36170212765957444 || alpha_T : 0.2839920188029697
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.42441860465116277 || alpha_T : 0.15233020449309942
------------------------------------------------------------
Iter 9-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434343 || alpha_T : 0.13207578752079352
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142857 || alpha_T : 0.11659694358385565
------------------------------------------------------------
Iter 11-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.448 || alpha_T : 0.1043774069310551
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4528985507246377 || alpha_T : 0.09448304975631158
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4569536423841059 || alpha_T : 0.08630637133349703
------------------------------------------------------------
Iter 14-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46036585365853655 || alpha_T : 0.0794349478794525
------------------------------------------------------------
Iter 15-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46327683615819215 || alpha_T : 0.07357882216814372
------------------------------------------------------------
Iter 16-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4657894736842106 || alpha_T : 0.06852812323397899
------------------------------------------------------------
Iter 17-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4679802955665025 || alpha_T : 0.06412716776183942
------------------------------------------------------------
Iter 18-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4699074074074074 || alpha_T : 0.060258012256226186
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.25000000000000006 || alpha_T : 0.5493061443340548
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.1904761904761905 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595744 || alpha_T : 0.2839920188029698
------------------------------------------------------------
Iter 6-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4109589041095891 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.43434343434343436 || alpha_T : 0.13207578752079335
------------------------------------------------------------
Iter 10-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.44196428571428575 || alpha_T : 0.11659694358385547
------------------------------------------------------------
Iter 11-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.44800000000000006 || alpha_T : 0.10437740693105492
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4528985507246377 || alpha_T : 0.09448304975631158
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4569536423841059 || alpha_T : 0.08630637133349703
------------------------------------------------------------
Iter 14-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46036585365853655 || alpha_T : 0.0794349478794525
------------------------------------------------------------
Iter 15-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4632768361581921 || alpha_T : 0.07357882216814392
------------------------------------------------------------
Iter 16-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46578947368421053 || alpha_T : 0.06852812323397908
------------------------------------------------------------
Iter 17-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4679802955665025 || alpha_T : 0.06412716776183942
------------------------------------------------------------
Iter 18-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46990740740740744 || alpha_T : 0.06025801225622609
------------------------------------------------------------
Iter 19-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.47161572052401757 || alpha_T : 0.05682965923626054
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619052 || alpha_T : 0.7234594914681626
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595744 || alpha_T : 0.2839920188029698
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.41095890410958913 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511629 || alpha_T : 0.1523302044930992
------------------------------------------------------------
Iter 9-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.43434343434343436 || alpha_T : 0.13207578752079335
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142857 || alpha_T : 0.11659694358385565
------------------------------------------------------------
Iter 11-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44799999999999995 || alpha_T : 0.10437740693105518
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.45289855072463764 || alpha_T : 0.09448304975631168
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4569536423841059 || alpha_T : 0.08630637133349703
------------------------------------------------------------
Iter 14-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46036585365853655 || alpha_T : 0.0794349478794525
------------------------------------------------------------
Iter 15-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46327683615819215 || alpha_T : 0.07357882216814372
------------------------------------------------------------
Iter 16-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46578947368421053 || alpha_T : 0.06852812323397908
------------------------------------------------------------
Iter 17-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4679802955665025 || alpha_T : 0.06412716776183942
------------------------------------------------------------
Iter 18-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46990740740740733 || alpha_T : 0.06025801225622628
------------------------------------------------------------
Iter 19-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.47161572052401746 || alpha_T : 0.05682965923626074
------------------------------------------------------------
Iter 20-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.47314049586776863 || alpha_T : 0.053770770802093165
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.1904761904761905 || alpha_T : 0.7234594914681627
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595745 || alpha_T : 0.28399201880296965
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.41095890410958913 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511628 || alpha_T : 0.15233020449309928
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434343 || alpha_T : 0.13207578752079352
------------------------------------------------------------
Iter 10-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4419642857142856 || alpha_T : 0.11659694358385583
------------------------------------------------------------
Iter 11-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44799999999999995 || alpha_T : 0.10437740693105518
------------------------------------------------------------
Iter 12-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.45289855072463764 || alpha_T : 0.09448304975631168
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.45695364238410596 || alpha_T : 0.08630637133349685
------------------------------------------------------------
Iter 14-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4603658536585366 || alpha_T : 0.07943494787945231
------------------------------------------------------------
Iter 15-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46327683615819215 || alpha_T : 0.07357882216814372
------------------------------------------------------------
Iter 16-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.46578947368421053 || alpha_T : 0.06852812323397908
------------------------------------------------------------
Iter 17-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4679802955665025 || alpha_T : 0.06412716776183942
------------------------------------------------------------
Iter 18-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46990740740740744 || alpha_T : 0.06025801225622609
------------------------------------------------------------
Iter 19-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4716157205240175 || alpha_T : 0.05682965923626064
------------------------------------------------------------
Iter 20-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4731404958677686 || alpha_T : 0.053770770802093366
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[ 1.  1.  1. -1. -1. -1. -1. -1.]
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=d22a6dca-ccc1-485b-98a9-638f320dced4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [266]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">21</span><span class="p">),</span><span class="n">error</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">21</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s1">'the N-th classifier'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">21</span><span class="p">),</span><span class="n">pre_err</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">21</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"k"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s1">'MultiSource-TrAdaBoost'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'error rate'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'iterations'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">21</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.50</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'iteration number.png'</span><span class="p">,</span><span class="n">bbox_inches</span> <span class="o">=</span> <span class="s1">'tight'</span><span class="p">,</span><span class="n">dpi</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bf39b7f1-671e-464d-a5ef-1aff1c57190b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Key-Differences-from-TrAdaBoost:">Key Differences from TrAdaBoost:<a class="anchor-link" href="#Key-Differences-from-TrAdaBoost:">¶</a></h3><h4 id="1.-Multiple-Source-Domains:">1. Multiple Source Domains:<a class="anchor-link" href="#1.-Multiple-Source-Domains:">¶</a></h4><ul>
<li><strong>TrAdaBoost</strong>: Utilizes knowledge from a single source domain.</li>
<li><strong>MultiSource-TrAdaBoost</strong>: Integrates knowledge from multiple source domains, allowing for a richer and more diverse set of information to be transferred.</li>
</ul>
<h4 id="2.-Weight-Adjustment-Mechanism:">2. Weight Adjustment Mechanism:<a class="anchor-link" href="#2.-Weight-Adjustment-Mechanism:">¶</a></h4><ul>
<li><strong>TrAdaBoost</strong>: Adjusts weights for instances from a single source domain and the target domain.</li>
<li><strong>MultiSource-TrAdaBoost</strong>: Adjusts weights for instances from each source domain individually and combines them with the target domain instances. This allows for more nuanced weight adjustments based on the relevance of each source domain to the target domain.</li>
</ul>
<h4 id="3.-Handling-Data-Distribution:">3. Handling Data Distribution:<a class="anchor-link" href="#3.-Handling-Data-Distribution:">¶</a></h4><ul>
<li><strong>TrAdaBoost</strong>: Assumes that the source and target domains may have different distributions but focuses on a single source.</li>
<li><strong>MultiSource-TrAdaBoost</strong>: Explicitly handles multiple sources with potentially different distributions, making it more flexible in complex transfer learning scenarios.</li>
</ul>
<h4 id="4.-Model-Robustness:">4. Model Robustness:<a class="anchor-link" href="#4.-Model-Robustness:">¶</a></h4><p><strong>TrAdaBoost</strong>: Risk of negative transfer if the single source domain is not well-aligned with the target domain.
<strong>ultiSource-TrAdaBoost</strong>: Reduces the risk of negative transfer by selecting and combining multiple sources, which can provide a more robust model.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e960f7d6-32c9-42e4-b3b7-583792e06cea">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Introduction-to-Task">Introduction to Task<a class="anchor-link" href="#Introduction-to-Task">¶</a></h2><p>TaskTrAdaBoost is a transfer learning algorithm designed to handle multi-source transfer learning tasks. It is an extension of the traditional Adaboost algorithm, specifically tailored to leverage multiple source domains to improve the performance on a target domain. This approach is particularly useful when the target domain has limited labeled data, but there are multiple related source domains with abundant labeled data. Task-TrAdaBoost takes
the parameter-transfer approach and both instance-transfer and parameter-transfer approaches belong to the inductive transfer learning. The parameter-transfer approach admits that the target classifier model shares some parameters with the most closely related sources, identifies these shared
parameters from various sources and uses them together with the target training data to improve the target classifier learning.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0fb202a1-d9f1-4e77-b4c9-2266ec74251f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Function-Definition-and-Explanation">Function Definition and Explanation<a class="anchor-link" href="#Function-Definition-and-Explanation">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=d373edb9-d469-4adc-9117-2ad008190248">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [270]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">TaskTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span><span class="n">gamma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Boosting for MultiSource Transfer Learning.</span>

<span class="sd">    Please feel free to open issues in the Github : https://github.com/Bin-Cao/TrAdaboost</span>
<span class="sd">    or </span>
<span class="sd">    contact Bin Cao (bcao@shu.edu.cn)</span>
<span class="sd">    in case of any problems/comments/suggestions in using the code. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    trans_S : feature matrix of same-distribution training data</span>

<span class="sd">    Multi_trans_A : dict, feature matrix of diff-distribution training data</span>
<span class="sd">    e.g.,</span>
<span class="sd">    Multi_trans_A = {</span>
<span class="sd">    'trans_A_1' :  data_1 , </span>
<span class="sd">    'trans_A_2' : data_2 ,</span>
<span class="sd">    ......</span>
<span class="sd">    }</span>
<span class="sd">    data_1 : feature matrix of diff-distribution training dataset 1</span>
<span class="sd">    data_2 : feature matrix of diff-distribution training dataset 2</span>

<span class="sd">    label_S : label of same-distribution training data, -1 or 1</span>

<span class="sd">    Multi_label_A : dict, label of diff-distribution training data, -1 or 1</span>
<span class="sd">    e.g.,</span>
<span class="sd">    Multi_label_A = {</span>
<span class="sd">    'label_A_1' :  label_1 , </span>
<span class="sd">    'label_A_2' : label_2 ,</span>
<span class="sd">    ......</span>
<span class="sd">    }</span>
<span class="sd">    label_1 : label of diff-distribution training dataset 1, -1 or 1</span>
<span class="sd">    label_1 : label of diff-distribution training dataset 2, -1 or 1</span>

<span class="sd">    test : feature matrix of test data</span>

<span class="sd">    N : int, default=20</span>
<span class="sd">    the number of weak estimators</span>
<span class="sd">    </span>
<span class="sd">    gamma : float, for avoiding overfitting </span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Yao, Y., &amp; Doretto, G. (2010, June)</span>
<span class="sd">    Boosting for transfer learning with multiple sources. IEEE.</span>
<span class="sd">    DOI: 10.1109/CVPR.2010.5539857</span>

<span class="sd">    """</span>
    <span class="n">weak_classifiers_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)):</span>
        <span class="n">trans_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">source</span><span class="p">]</span>
        <span class="n">label_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">source</span><span class="p">]</span>

        <span class="n">trans_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
        <span class="n">label_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">label_A</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    
        <span class="c1"># initial weight</span>
        <span class="n">row_A</span> <span class="o">=</span> <span class="n">trans_A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">weights_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_A</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">weights_A</span> <span class="o">=</span> <span class="n">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights_A</span><span class="p">)</span>
            <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">"gini"</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="s2">"log2"</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="s2">"best"</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">weak_classifier</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">label_A</span><span class="p">,</span> <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">weights_A</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">pre</span> <span class="o">=</span> <span class="n">weak_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">trans_A</span><span class="p">)</span>
            <span class="n">error_rate</span> <span class="o">=</span> <span class="n">calculate_error_rate</span><span class="p">(</span><span class="n">label_A</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">weights_A</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">error_rate</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">error_rate</span><span class="o">+</span><span class="mf">1e-10</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">error_rate</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="n">gamma</span><span class="p">:</span>
                <span class="n">weak_classifiers_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weak_classifier</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_A</span><span class="p">):</span>
                <span class="n">weights_A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights_A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span>  <span class="n">pre</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">label_A</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The the set of candidate weak classifiers is initilized and contains </span><span class="si">{}</span><span class="s1"> classifier'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weak_classifiers_set</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The phase-I of TaskTrAdaBoost is finished'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
    
    <span class="n">row_S</span> <span class="o">=</span> <span class="n">trans_S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">row_T</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    
    <span class="c1"># initial weight</span>
    <span class="n">weights_S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_S</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">row_T</span><span class="p">])</span>
    <span class="n">alpha_T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
    <span class="n">result_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span> <span class="o">+</span> <span class="n">row_T</span><span class="p">,</span> <span class="n">N</span><span class="p">])</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">'params initial finished.'</span><span class="p">)</span>

    <span class="n">error_rate_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">weights_S</span> <span class="o">=</span> <span class="n">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights_S</span><span class="p">)</span>
        <span class="n">error_rate_set</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># save the prediction results of weak classifiers</span>
        <span class="n">_result_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_S</span> <span class="o">+</span> <span class="n">row_T</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">weak_classifiers_set</span><span class="p">)])</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weak_classifiers_set</span><span class="p">)):</span>
            <span class="n">_result_label</span><span class="p">[:,</span><span class="n">item</span><span class="p">]</span> <span class="o">=</span> <span class="n">weak_classifiers_set</span><span class="p">[</span><span class="n">item</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
            <span class="n">_error</span> <span class="o">=</span> <span class="n">calculate_error_rate</span><span class="p">(</span><span class="n">label_S</span><span class="p">,</span> <span class="n">_result_label</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">row_S</span><span class="p">,</span> <span class="n">item</span><span class="p">],</span> <span class="n">weights_S</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_error</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">_error</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">_error</span> 
                <span class="c1"># for a binary classifier </span>
                <span class="c1"># reverse the prediction label -1 to 1; 1 to -1.</span>
                <span class="n">pre_labels</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">_result_label</span><span class="p">[:,</span> <span class="n">item</span><span class="p">])</span>
                <span class="n">_result_label</span><span class="p">[:,</span> <span class="n">item</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">pre_labels</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="n">error_rate_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_error</span><span class="p">)</span>
        <span class="n">error_rate_set</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">error_rate_set</span><span class="p">)</span>
       
        <span class="c1"># choise the best weak classifier and remove it from the set </span>
        <span class="n">classifier_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">error_rate_set</span> <span class="o">==</span> <span class="n">error_rate_set</span><span class="o">.</span><span class="n">min</span><span class="p">()))</span>
        <span class="n">result_label</span><span class="p">[:,</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">_result_label</span><span class="p">[:,</span><span class="n">classifier_index</span><span class="p">]</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">error_rate_set</span><span class="p">[</span><span class="n">classifier_index</span><span class="p">]</span>
        <span class="n">error_rate_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weak_classifiers_set</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">error</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span> <span class="k">break</span>
        <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="n">error</span><span class="p">)</span> 
        <span class="n">weak_classifiers_set</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">classifier_index</span><span class="p">)</span>

        
       <span class="c1"># Changing the data weights of same-distribution training data</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_S</span><span class="p">):</span>
            <span class="n">weights_S</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights_S</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">result_label</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">label_S</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Iter </span><span class="si">{}</span><span class="s1">-th result :'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'error rate :'</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="s1">'|| alpha_T :'</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error</span><span class="p">)</span> <span class="o">/</span> <span class="n">error</span><span class="p">)</span> <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'-'</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_T</span><span class="p">):</span>
        <span class="n">res_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">result_label</span><span class="p">[</span><span class="n">row_S</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">alpha_T</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">if</span> <span class="n">res_</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The phase-II of TaskTrAdaBoost is finished'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'='</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'The prediction labels of test data are :'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">predict</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">error_rate_list</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_error_rate</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_P</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="n">sign</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_P</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sign</span><span class="p">(</span><span class="n">label_R</span><span class="p">,</span> <span class="n">label_P</span><span class="p">):</span>
    <span class="n">_res</span> <span class="o">=</span> <span class="n">label_R</span> <span class="o">-</span> <span class="n">label_P</span> 
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_R</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">_res</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">_res</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">_res</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1859db41-2a3f-4f83-99e5-93b1816dff80">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.-Parameters">1. Parameters<a class="anchor-link" href="#1.-Parameters">¶</a></h3><ul>
<li><code>trans_S</code>: Feature matrix of the target domain (same-distribution training data).</li>
<li><code>Multi_trans_A</code>: Dictionary containing feature matrices of multiple source domains (different-distribution training data).</li>
<li><code>label_S</code>: Labels of the target domain.</li>
<li><code>Multi_label_A</code>: Dictionary containing labels of multiple source domains.</li>
<li><code>test</code>: Feature matrix of the test data.</li>
<li><code>N</code>: Number of weak estimators (iterations).</li>
<li><code>gamma</code>: Threshold to avoid overfitting.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=35da56a0-6137-49e4-8128-87415df299b3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="2.-Phase-I:-Initializing-Weak-Classifiers">2. Phase I: Initializing Weak Classifiers<a class="anchor-link" href="#2.-Phase-I:-Initializing-Weak-Classifiers">¶</a></h3><p>In this phase, the algorithm initializes a set of weak classifiers using the source domains.</p>
<p><strong>Iterate over source domains</strong>:</p>
<ul>
<li>For each source domain, initialize the weights for the samples.</li>
<li>Train a weak classifier (decision tree) using the weighted samples.</li>
<li>Calculate the error rate of the classifier.</li>
<li>If the error rate is below a threshold (0.5) and the alpha value (confidence) is greater than gamma, add the classifier to the set of weak classifiers.</li>
<li>Update the weights of the samples based on the classifier's performance.</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="p">)):</span>
    <span class="n">trans_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_trans_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">source</span><span class="p">]</span>
    <span class="n">label_A</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Multi_label_A</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">source</span><span class="p">]</span>

    <span class="n">trans_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>
    <span class="n">label_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">label_A</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">'C'</span><span class="p">)</span>

    <span class="c1"># Initial weight</span>
    <span class="n">row_A</span> <span class="o">=</span> <span class="n">trans_A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">weights_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">row_A</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">row_A</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">weights_A</span> <span class="o">=</span> <span class="n">calculate_ratio_weight</span><span class="p">(</span><span class="n">weights_A</span><span class="p">)</span>
        <span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">"gini"</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="s2">"log2"</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="s2">"best"</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weak_classifier</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trans_A</span><span class="p">,</span> <span class="n">label_A</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights_A</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">pre</span> <span class="o">=</span> <span class="n">weak_classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">trans_A</span><span class="p">)</span>
        <span class="n">error_rate</span> <span class="o">=</span> <span class="n">calculate_error_rate</span><span class="p">(</span><span class="n">label_A</span><span class="p">,</span> <span class="n">pre</span><span class="p">,</span> <span class="n">weights_A</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">error_rate</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">error_rate</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">error_rate</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">alpha</span> <span class="o">&gt;</span> <span class="n">gamma</span><span class="p">:</span>
            <span class="n">weak_classifiers_set</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weak_classifier</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">row_A</span><span class="p">):</span>
            <span class="n">weights_A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights_A</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">pre</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">label_A</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e3137b54-34be-48dd-934e-7bf2bf3ecf87">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="3.-Phase-II:-Boosting-on-Target-Domain">3. Phase II: Boosting on Target Domain<a class="anchor-link" href="#3.-Phase-II:-Boosting-on-Target-Domain">¶</a></h3><p>In this phase, the algorithm uses the weak classifiers to iteratively improve the performance on the target domain.</p>
<p><strong>Initialize Weights for Target Domain</strong>:</p>
<ul>
<li>Initialize the weights for the samples in the target domain.</li>
<li>Combine the target domain data with the test data for prediction.</li>
</ul>
<p><strong>Iterate Over Weak Classifiers</strong>:</p>
<ul>
<li>For each iteration, select the best weak classifier from the set.</li>
<li>Calculate the error rate of the classifier on the target domain.</li>
<li>Update the weights of the target domain samples based on the classifier's performance.</li>
<li>Remove the selected classifier from the set.</li>
</ul>
<p><strong>Predict Test Data</strong>:</p>
<ul>
<li>Use the selected weak classifiers to predict the labels of the test data.</li>
<li>Combine the predictions using the alpha values (confidence) to get the final prediction.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fd2fecdb-c006-416c-99b7-873df2d7c322">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Experiment">Experiment<a class="anchor-link" href="#Experiment">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=befa1a3a-eb25-4abf-a73c-f4635eff4ee6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1.-Load-Data">1. Load Data<a class="anchor-link" href="#1.-Load-Data">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e51bcfb8-e293-4b2b-8ac2-13445d49e995">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [276]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Sdata.csv'</span><span class="p">)</span>
<span class="c1"># two diff-distribution training data</span>
<span class="n">A1_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Adata1.csv'</span><span class="p">)</span>
<span class="n">A2_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Adata2.csv'</span><span class="p">)</span>
<span class="c1"># test data</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'M_Tdata.csv'</span><span class="p">)</span>

<span class="n">Multi_trans_A</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">'trans_A_1'</span> <span class="p">:</span> <span class="n">A1_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
<span class="s1">'trans_A_2'</span> <span class="p">:</span> <span class="n">A2_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">Multi_label_A</span> <span class="o">=</span> <span class="p">{</span>
<span class="s1">'label_A_1'</span> <span class="p">:</span>  <span class="n">A1_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> 
<span class="s1">'label_A_2'</span> <span class="p">:</span>  <span class="n">A2_train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span>
<span class="p">}</span>
<span class="n">trans_S</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">label_S</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6f84eeba-d218-48cd-a37a-bc763b1fe6af">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="2.-Prediction-and-Visualization">2. Prediction and Visualization<a class="anchor-link" href="#2.-Prediction-and-Visualization">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=64b85b36-168a-40dd-ad6d-2fd0aef87ac3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [278]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">pred</span><span class="p">,</span> <span class="n">error</span> <span class="o">=</span> <span class="n">TaskTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,)</span>

<span class="n">N_iter</span> <span class="o">=</span> <span class="mi">21</span>
<span class="n">pre_err</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_iter</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">pre</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">TaskTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">trans_S</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,)</span>
    <span class="n">pre_err</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">pre</span> <span class="o">-</span> <span class="n">label_S</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">trans_S</span><span class="p">))</span>

<span class="n">pred</span><span class="p">,</span> <span class="n">error</span> <span class="o">=</span> <span class="n">MultiSourceTrAdaBoost</span><span class="p">(</span><span class="n">trans_S</span><span class="p">,</span> <span class="n">Multi_trans_A</span><span class="p">,</span> <span class="n">label_S</span><span class="p">,</span> <span class="n">Multi_label_A</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">N_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>The the set of candidate weak classifiers is initilized and contains 10 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[ 1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 2 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.3529411764705882 || alpha_T : 0.30306790178515786
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 4 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.3529411764705882 || alpha_T : 0.30306790178515786
------------------------------------------------------------
Iter 1-th result :
error rate : 0.46212121212121215 || alpha_T : 0.07590300643400197
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 6 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.3529411764705882 || alpha_T : 0.30306790178515786
------------------------------------------------------------
Iter 1-th result :
error rate : 0.46212121212121215 || alpha_T : 0.07590300643400197
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47171553913645803 || alpha_T : 0.05662937884103338
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 8 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.3529411764705882 || alpha_T : 0.30306790178515786
------------------------------------------------------------
Iter 1-th result :
error rate : 0.46212121212121215 || alpha_T : 0.07590300643400197
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47171553913645803 || alpha_T : 0.05662937884103338
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4788119140404382 || alpha_T : 0.04240156481239518
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 10 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 12 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 14 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 16 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 18 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 19 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 20 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
Iter 10-th result :
error rate : 0.493169548648307 || alpha_T : 0.013661752598969637
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 22 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.49212413137148636 || alpha_T : 0.015753040210124657
------------------------------------------------------------
Iter 10-th result :
error rate : 0.4931695486483068 || alpha_T : 0.013661752598970069
------------------------------------------------------------
Iter 11-th result :
error rate : 0.4940750949165553 || alpha_T : 0.011850364855841634
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 23 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
Iter 10-th result :
error rate : 0.493169548648307 || alpha_T : 0.013661752598969637
------------------------------------------------------------
Iter 11-th result :
error rate : 0.49407509491655544 || alpha_T : 0.011850364855841417
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972415 || alpha_T : 0.010280628716336638
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 25 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.49212413137148636 || alpha_T : 0.015753040210124657
------------------------------------------------------------
Iter 10-th result :
error rate : 0.4931695486483068 || alpha_T : 0.013661752598970069
------------------------------------------------------------
Iter 11-th result :
error rate : 0.4940750949165553 || alpha_T : 0.011850364855841634
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972426 || alpha_T : 0.01028062871633642
------------------------------------------------------------
Iter 13-th result :
error rate : 0.4955402217875542 || alpha_T : 0.008919792978321028
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 27 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
Iter 10-th result :
error rate : 0.493169548648307 || alpha_T : 0.013661752598969637
------------------------------------------------------------
Iter 11-th result :
error rate : 0.49407509491655544 || alpha_T : 0.011850364855841417
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972415 || alpha_T : 0.010280628716336638
------------------------------------------------------------
Iter 13-th result :
error rate : 0.49554022178755397 || alpha_T : 0.008919792978321463
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468544 || alpha_T : 0.007739722047545406
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 28 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.49212413137148636 || alpha_T : 0.015753040210124657
------------------------------------------------------------
Iter 10-th result :
error rate : 0.4931695486483068 || alpha_T : 0.013661752598970069
------------------------------------------------------------
Iter 11-th result :
error rate : 0.4940750949165553 || alpha_T : 0.011850364855841634
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972426 || alpha_T : 0.01028062871633642
------------------------------------------------------------
Iter 13-th result :
error rate : 0.4955402217875542 || alpha_T : 0.008919792978321028
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468546 || alpha_T : 0.00773972204754486
------------------------------------------------------------
Iter 15-th result :
error rate : 0.49664195781358356 || alpha_T : 0.006716185353661329
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 29 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
Iter 10-th result :
error rate : 0.493169548648307 || alpha_T : 0.013661752598969637
------------------------------------------------------------
Iter 11-th result :
error rate : 0.49407509491655544 || alpha_T : 0.011850364855841417
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972415 || alpha_T : 0.010280628716336638
------------------------------------------------------------
Iter 13-th result :
error rate : 0.49554022178755397 || alpha_T : 0.008919792978321463
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468544 || alpha_T : 0.007739722047545406
------------------------------------------------------------
Iter 15-th result :
error rate : 0.49664195781358333 || alpha_T : 0.006716185353661767
------------------------------------------------------------
Iter 16-th result :
error rate : 0.49708589505225254 || alpha_T : 0.005828275887777219
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 30 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.49212413137148636 || alpha_T : 0.015753040210124657
------------------------------------------------------------
Iter 10-th result :
error rate : 0.4931695486483068 || alpha_T : 0.013661752598970069
------------------------------------------------------------
Iter 11-th result :
error rate : 0.4940750949165553 || alpha_T : 0.011850364855841634
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972426 || alpha_T : 0.01028062871633642
------------------------------------------------------------
Iter 13-th result :
error rate : 0.4955402217875542 || alpha_T : 0.008919792978321028
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468546 || alpha_T : 0.00773972204754486
------------------------------------------------------------
Iter 15-th result :
error rate : 0.49664195781358356 || alpha_T : 0.006716185353661329
------------------------------------------------------------
Iter 16-th result :
error rate : 0.4970858950522526 || alpha_T : 0.005828275887777219
------------------------------------------------------------
Iter 17-th result :
error rate : 0.49747105734781644 || alpha_T : 0.005057928435646537
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 31 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
Iter 10-th result :
error rate : 0.493169548648307 || alpha_T : 0.013661752598969637
------------------------------------------------------------
Iter 11-th result :
error rate : 0.49407509491655544 || alpha_T : 0.011850364855841417
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972415 || alpha_T : 0.010280628716336638
------------------------------------------------------------
Iter 13-th result :
error rate : 0.49554022178755397 || alpha_T : 0.008919792978321463
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468544 || alpha_T : 0.007739722047545406
------------------------------------------------------------
Iter 15-th result :
error rate : 0.49664195781358333 || alpha_T : 0.006716185353661767
------------------------------------------------------------
Iter 16-th result :
error rate : 0.49708589505225254 || alpha_T : 0.005828275887777219
------------------------------------------------------------
Iter 17-th result :
error rate : 0.4974710573478165 || alpha_T : 0.005057928435646537
------------------------------------------------------------
Iter 18-th result :
error rate : 0.49780525592962954 || alpha_T : 0.004389516332709675
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 32 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.47835497835497837 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.48385358145022317 || alpha_T : 0.03230406941275097
------------------------------------------------------------
Iter 5-th result :
error rate : 0.48603014886417145 || alpha_T : 0.02794697584037156
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540764 || alpha_T : 0.024196984583073004
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.49212413137148636 || alpha_T : 0.015753040210124657
------------------------------------------------------------
Iter 10-th result :
error rate : 0.4931695486483068 || alpha_T : 0.013661752598970069
------------------------------------------------------------
Iter 11-th result :
error rate : 0.4940750949165553 || alpha_T : 0.011850364855841634
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972426 || alpha_T : 0.01028062871633642
------------------------------------------------------------
Iter 13-th result :
error rate : 0.4955402217875542 || alpha_T : 0.008919792978321028
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468546 || alpha_T : 0.00773972204754486
------------------------------------------------------------
Iter 15-th result :
error rate : 0.49664195781358356 || alpha_T : 0.006716185353661329
------------------------------------------------------------
Iter 16-th result :
error rate : 0.4970858950522526 || alpha_T : 0.005828275887777219
------------------------------------------------------------
Iter 17-th result :
error rate : 0.49747105734781644 || alpha_T : 0.005057928435646537
------------------------------------------------------------
Iter 18-th result :
error rate : 0.4978052559296297 || alpha_T : 0.004389516332709345
------------------------------------------------------------
Iter 19-th result :
error rate : 0.49809525362616797 || alpha_T : 0.0038095111759091603
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
The the set of candidate weak classifiers is initilized and contains 33 classifier
The phase-I of TaskTrAdaBoost is finished
============================================================
params initial finished.
Iter 0-th result :
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
error rate : 0.34375 || alpha_T : 0.32331358246252623
------------------------------------------------------------
Iter 2-th result :
error rate : 0.4783549783549783 || alpha_T : 0.043317115986451146
------------------------------------------------------------
Iter 3-th result :
error rate : 0.4813184130977638 || alpha_T : 0.03738057479630225
------------------------------------------------------------
Iter 4-th result :
error rate : 0.4838535814502233 || alpha_T : 0.03230406941275076
------------------------------------------------------------
Iter 5-th result :
error rate : 0.4860301488641715 || alpha_T : 0.027946975840371455
------------------------------------------------------------
Iter 6-th result :
error rate : 0.4879038683540763 || alpha_T : 0.024196984583073216
------------------------------------------------------------
Iter 7-th result :
error rate : 0.48952013994447197 || alpha_T : 0.020962790190945574
------------------------------------------------------------
Iter 8-th result :
error rate : 0.49091645664127803 || alpha_T : 0.01816908575349449
------------------------------------------------------------
Iter 9-th result :
error rate : 0.4921241313714865 || alpha_T : 0.01575304021012444
------------------------------------------------------------
Iter 10-th result :
error rate : 0.493169548648307 || alpha_T : 0.013661752598969637
------------------------------------------------------------
Iter 11-th result :
error rate : 0.49407509491655544 || alpha_T : 0.011850364855841417
------------------------------------------------------------
Iter 12-th result :
error rate : 0.49485986672972415 || alpha_T : 0.010280628716336638
------------------------------------------------------------
Iter 13-th result :
error rate : 0.49554022178755397 || alpha_T : 0.008919792978321463
------------------------------------------------------------
Iter 14-th result :
error rate : 0.4961302162468544 || alpha_T : 0.007739722047545406
------------------------------------------------------------
Iter 15-th result :
error rate : 0.49664195781358333 || alpha_T : 0.006716185353661767
------------------------------------------------------------
Iter 16-th result :
error rate : 0.49708589505225254 || alpha_T : 0.005828275887777219
------------------------------------------------------------
Iter 17-th result :
error rate : 0.4974710573478165 || alpha_T : 0.005057928435646537
------------------------------------------------------------
Iter 18-th result :
error rate : 0.49780525592962954 || alpha_T : 0.004389516332709675
------------------------------------------------------------
Iter 19-th result :
error rate : 0.4980952536261679 || alpha_T : 0.0038095111759092705
------------------------------------------------------------
Iter 20-th result :
error rate : 0.49834690912274815 || alpha_T : 0.0033061938010282258
------------------------------------------------------------
The phase-II of TaskTrAdaBoost is finished
============================================================
The prediction labels of test data are :
[-1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.]
params initial finished.
============================================================
Iter 0-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.058823529411764705 || alpha_T : 1.3862943611198906
------------------------------------------------------------
Iter 1-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.12500000000000003 || alpha_T : 0.9729550745276565
------------------------------------------------------------
Iter 2-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.24999999999999997 || alpha_T : 0.5493061443340549
------------------------------------------------------------
Iter 3-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.19047619047619052 || alpha_T : 0.7234594914681626
------------------------------------------------------------
Iter 4-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.30882352941176466 || alpha_T : 0.40281258199331793
------------------------------------------------------------
Iter 5-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.3617021276595744 || alpha_T : 0.2839920188029698
------------------------------------------------------------
Iter 6-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.39166666666666666 || alpha_T : 0.22015591971916632
------------------------------------------------------------
Iter 7-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.41095890410958913 || alpha_T : 0.18000136701570338
------------------------------------------------------------
Iter 8-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4244186046511629 || alpha_T : 0.1523302044930992
------------------------------------------------------------
Iter 9-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.4343434343434344 || alpha_T : 0.1320757875207932
------------------------------------------------------------
Iter 10-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.44196428571428575 || alpha_T : 0.11659694358385547
------------------------------------------------------------
Iter 11-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.448 || alpha_T : 0.1043774069310551
------------------------------------------------------------
Iter 12-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.45289855072463764 || alpha_T : 0.09448304975631168
------------------------------------------------------------
Iter 13-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.45695364238410596 || alpha_T : 0.08630637133349685
------------------------------------------------------------
Iter 14-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4603658536585366 || alpha_T : 0.07943494787945231
------------------------------------------------------------
Iter 15-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46327683615819215 || alpha_T : 0.07357882216814372
------------------------------------------------------------
Iter 16-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.4657894736842105 || alpha_T : 0.06852812323397918
------------------------------------------------------------
Iter 17-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46798029556650245 || alpha_T : 0.06412716776183942
------------------------------------------------------------
Iter 18-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.46990740740740744 || alpha_T : 0.06025801225622609
------------------------------------------------------------
Iter 19-th result :
The 0-th diff-distribution training dataset is chosen to transfer
error rate : 0.47161572052401746 || alpha_T : 0.05682965923626074
------------------------------------------------------------
Iter 20-th result :
The 1-th diff-distribution training dataset is chosen to transfer
error rate : 0.47314049586776863 || alpha_T : 0.053770770802093165
------------------------------------------------------------
MultiSourceTrAdaBoost is done
============================================================
The prediction labels of test data are :
[ 1.  1.  1. -1. -1. -1. -1. -1.]
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=935cbb47-420d-4607-85e9-d7345e119c0c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [279]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">21</span><span class="p">),</span><span class="n">error</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">21</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s1">'the N-th classifier'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">21</span><span class="p">),</span><span class="n">pre_err</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">21</span><span class="p">],</span><span class="s1">'o-'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"k"</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span><span class="s1">'MultiSource-TrAdaBoost'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'error rate'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'iterations'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">21</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.50</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'iteration number.png'</span><span class="p">,</span><span class="n">bbox_inches</span> <span class="o">=</span> <span class="s1">'tight'</span><span class="p">,</span><span class="n">dpi</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=f381fc8a-3adf-4355-9c80-f770756f9a5d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Mechanisms:">Mechanisms:<a class="anchor-link" href="#Mechanisms:">¶</a></h2><p><strong>TrAdaBoost</strong>:</p>
<ul>
<li>In each iteration, it trains a weak classifier on the combined source and target data.</li>
<li>Misclassified target samples have their weights increased, while misclassified source samples have their weights decreased.</li>
<li>The final classifier is a weighted combination of the weak classifiers.</li>
</ul>
<p><strong>TaskTrAdaBoost</strong>:</p>
<ul>
<li>Phase I: Initializes a set of weak classifiers by training on each source domain separately.</li>
<li>Phase II: Selects the best weak classifiers from the set and iteratively improves the target classifier by re-weighting the target samples based on the performance of the weak classifiers.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=8f905758-2d4d-47a8-b745-89451f0463d9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
